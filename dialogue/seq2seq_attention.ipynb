{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Layer, Input, Embedding, LSTM, Dense, Attention\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    raw_source_data =  \"./data/ch_source_data_seg.txt\"\n",
    "    raw_target_data = \"data/ch_target_data_seg.txt\"\n",
    "    vocab_file = \"./data/ch_word_vocab.txt\"\n",
    "    num_sample = 10000\n",
    "    \n",
    "    maxlen = 10\n",
    "    embedding_dim = 50\n",
    "    hidden_units = 64\n",
    "    \n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    val_rate = 0.2\n",
    "    \n",
    "    model_file = \"./output/seq2seq_attention_weights.h5\"\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['许兵', '是', '谁']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['是', '我', '善良', '可爱', '的', '主人', '的', '老公', '啊']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(data_path):\n",
    "    datas = []\n",
    "    with open(data_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            datas.append(words)\n",
    "    return datas\n",
    "\n",
    "source_data = read_data(config.raw_source_data)[:config.num_sample]\n",
    "target_data = read_data(config.raw_target_data)[:config.num_sample]\n",
    "source_data[10]\n",
    "target_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab test:  ['<PAD>', '<UNK>', '<GO>', '<EOS>', '呵呵', '不是', '怎么', '了', '开心', '点']\n"
     ]
    }
   ],
   "source": [
    "def read_vocab(vocab_file):\n",
    "    vocab_words = []\n",
    "    with open(vocab_file, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            vocab_words.append(line.strip())\n",
    "    return vocab_words\n",
    "\n",
    "vocab_words = read_vocab(config.vocab_file)\n",
    "special_words = [\"<PAD>\", \"<UNK>\", \"<GO>\", \"<EOS>\"]\n",
    "vocab_words = special_words + vocab_words\n",
    "\n",
    "vocab2id = {word: i for i, word in enumerate(vocab_words)}\n",
    "id2vocab = {i: word for i, word in enumerate(vocab_words)}\n",
    "print(\"vocab test: \", [id2vocab[i] for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 27, 24]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[27, 16, 9572, 436, 45, 452, 45, 274, 111]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_data_index(datas, vocab2id):\n",
    "    data_indexs = []\n",
    "    for words in datas:\n",
    "        line_index = [vocab2id[w] if w in vocab2id else vocab2id[\"<UNK>\"] for w in words]\n",
    "        data_indexs.append(line_index)\n",
    "    return data_indexs\n",
    "\n",
    "source_data_ids = process_data_index(source_data, vocab2id)\n",
    "target_data_ids = process_data_index(target_data, vocab2id)\n",
    "source_data_ids[10]\n",
    "target_data_ids[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder: 一个Embedding层，加上LSTM层\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.encoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name=\"encode_lstm\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoder_embed = self.embedding(inputs)\n",
    "        encoder_outputs, state_h, state_c = self.encoder_lstm(encoder_embed)\n",
    "        return encoder_outputs, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder: 有三部分输入，一是encoder部分的每个时刻输出，二是encoder的隐藏状态输出，三是decoder的目标输入\n",
    "# decoder还包含一个Attention层，计算decoder每个输入与encoder的注意力\n",
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name=\"decode_lstm\")\n",
    "        self.attention = Attention()\n",
    "    \n",
    "    def call(self, enc_outputs, dec_inputs, states_inputs):\n",
    "        decoder_embed = self.embedding(dec_inputs)\n",
    "        dec_outputs, dec_state_h, dec_state_c = self.decoder_lstm(decoder_embed, initial_state=states_inputs)\n",
    "        attention_output = self.attention([dec_outputs, enc_outputs])\n",
    "        \n",
    "        return attention_output, dec_state_h, dec_state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Seq2Seq(maxlen, embedding_dim, hidden_units, vocab_size):\n",
    "    # Input Layer\n",
    "    encoder_inputs = Input(shape=(maxlen,), name=\"encode_input\")\n",
    "    decoder_inputs = Input(shape=(None,), name=\"decode_input\")\n",
    "    # Encoder Layer\n",
    "    encoder = Encoder(vocab_size, embedding_dim, hidden_units)\n",
    "    enc_outputs, enc_state_h, enc_state_c = encoder(encoder_inputs)\n",
    "    dec_states_inputs = [enc_state_h, enc_state_c]\n",
    "    # Decoder Layer\n",
    "    decoder = Decoder(vocab_size, embedding_dim, hidden_units)\n",
    "    attention_output, dec_state_h, dec_state_c = decoder(enc_outputs, decoder_inputs, dec_states_inputs)\n",
    "    # Dense Layer\n",
    "    dense_outputs = Dense(vocab_size, activation='softmax', name=\"dense\")(attention_output)\n",
    "    # seq2seq model\n",
    "    model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=dense_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs:  [[2, 4, 3], [2, 5, 3]]\n",
      "decoder inputs:  [[2, 27, 37846, 756, 45, 180], [2, 38, 27, 84, 49272]]\n",
      "decoder outputs:  [[27, 37846, 756, 45, 180, 3], [38, 27, 84, 49272, 3]]\n"
     ]
    }
   ],
   "source": [
    "def process_input_data(source_data_ids, target_data_ids, vocab2id):\n",
    "    \"\"\"\n",
    "    输入输出加上开始结束标识\n",
    "    \"\"\"\n",
    "    source_inputs = []\n",
    "    decoder_inputs, decoder_outputs = [], []\n",
    "    for source, target in zip(source_data_ids, target_data_ids):\n",
    "        source_inputs.append([vocab2id[\"<GO>\"]] + source + [vocab2id[\"<EOS>\"]])\n",
    "        decoder_inputs.append([vocab2id[\"<GO>\"]] + target)\n",
    "        decoder_outputs.append(target + [vocab2id[\"<EOS>\"]])\n",
    "    return source_inputs, decoder_inputs, decoder_outputs\n",
    "\n",
    "source_input_ids, target_input_ids, target_output_ids = process_input_data(source_data_ids, target_data_ids, vocab2id)\n",
    "len(source_input_ids)\n",
    "len(target_input_ids)\n",
    "len(target_output_ids)\n",
    "print(\"encoder inputs: \", source_input_ids[:2])\n",
    "print(\"decoder inputs: \", target_input_ids[:2])\n",
    "print(\"decoder outputs: \", target_output_ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [5], [6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 11, 20]]\n",
      "[[    2    27 37846   756    45   180     0     0     0     0]\n",
      " [    2    38    27    84 49272     0     0     0     0     0]\n",
      " [    2    16  6692    82 49273   320    16   518     0     0]\n",
      " [    2   526     0     0     0     0     0     0     0     0]\n",
      " [   16   438    22   328    19 49272 15817   254  1764 49272]]\n",
      "[[   27 37846   756    45   180     3     0     0     0     0]\n",
      " [   38    27    84 49272     3     0     0     0     0     0]\n",
      " [   16  6692    82 49273   320    16   518     3     0     0]\n",
      " [  526     3     0     0     0     0     0     0     0     0]\n",
      " [  438    22   328    19 49272 15817   254  1764 49272     3]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "source_input_ids = pad_sequences(source_input_ids, padding='post', maxlen=config.maxlen)\n",
    "target_input_ids = pad_sequences(target_input_ids, padding='post',  maxlen=config.maxlen)\n",
    "target_output_ids = pad_sequences(target_output_ids, padding='post',  maxlen=config.maxlen)\n",
    "source_input_ids.shape\n",
    "target_input_ids.shape\n",
    "target_output_ids.shape\n",
    "print(source_data_ids[:5])\n",
    "print(target_input_ids[:5])\n",
    "print(target_output_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encode_input (InputLayer)       [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Encoder)               ((None, 10, 64), (No 3536140     encode_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decode_input (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               ((None, None, 64), ( 3536140     encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 70134)  4558710     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,630,990\n",
      "Trainable params: 11,630,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "vocab_size = len(vocab2id)\n",
    "model = Seq2Seq(config.maxlen, config.embedding_dim, config.hidden_units, vocab_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 234s 29ms/sample - loss: 8.7961 - val_loss: 8.0049\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 177s 22ms/sample - loss: 7.8481 - val_loss: 7.8211\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 174s 22ms/sample - loss: 7.5858 - val_loss: 7.5983\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 198s 25ms/sample - loss: 7.3377 - val_loss: 7.4236\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 234s 29ms/sample - loss: 7.1060 - val_loss: 7.2403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04640ea890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "model.fit([source_input_ids, target_input_ids], target_output_ids, \n",
    "          batch_size=config.batch_size, epochs=config.epochs, validation_split=config.val_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(config.model_file)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encode_input (InputLayer)       [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Encoder)               ((None, 10, 64), (No 3536140     encode_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decode_input (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               ((None, None, 64), ( 3536140     encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 70134)  4558710     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,630,990\n",
      "Trainable params: 11,630,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# 新加载时，需要先重新定义模型，然后load_weights加载权重\n",
    "model = Seq2Seq(config.maxlen, config.embedding_dim, config.hidden_units, vocab_size)\n",
    "model.load_weights(config.model_file)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取Encoder子模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encode_input (InputLayer)    [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "encoder (Encoder)            ((None, 10, 64), (None, 6 3536140   \n",
      "=================================================================\n",
      "Total params: 3,536,140\n",
      "Trainable params: 3,536,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# encoder_model用于对输入编码\n",
    "def encoder_infer(model):\n",
    "    encoder_model = Model(inputs=model.get_layer('encoder').inputs, \n",
    "                        outputs=model.get_layer('encoder').outputs)\n",
    "    return encoder_model\n",
    "\n",
    "encoder_model = encoder_infer(model)\n",
    "print(encoder_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取Decoder子模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_output (InputLayer)         [(None, 10, 64)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decode_input (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_state_h (InputLayer)      [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_state_c (InputLayer)      [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               ((None, None, 64), ( 3536140     enc_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 70134)  4558710     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,094,850\n",
      "Trainable params: 8,094,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# decoder_model用于对输出按每个时刻解码\n",
    "def decoder_infer(model, encoder_model):\n",
    "    encoder_output = encoder_model.get_layer('encoder').output[0]\n",
    "    maxlen, hidden_units = encoder_output.shape[1:]\n",
    "    \n",
    "    dec_input = model.get_layer('decode_input').input\n",
    "    enc_output = Input(shape=(maxlen, hidden_units), name='enc_output')\n",
    "    dec_input_state_h = Input(shape=(hidden_units,), name='input_state_h')\n",
    "    dec_input_state_c = Input(shape=(hidden_units,), name='input_state_c')\n",
    "    dec_input_states = [dec_input_state_h, dec_input_state_c]\n",
    "\n",
    "    decoder = model.get_layer('decoder')\n",
    "    dec_outputs, out_state_h, out_state_c = decoder(enc_output, dec_input, dec_input_states)\n",
    "    dec_output_states = [out_state_h, out_state_c]\n",
    "\n",
    "    decoder_dense = model.get_layer('dense')\n",
    "    dense_output = decoder_dense(dec_outputs)\n",
    "\n",
    "    decoder_model = Model(inputs=[enc_output, dec_input, dec_input_states], \n",
    "                          outputs=[dense_output]+dec_output_states)\n",
    "    return decoder_model\n",
    "\n",
    "decoder_model = decoder_infer(model, encoder_model)\n",
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_predict(input_text, encoder_model, decoder_model, maxlen):\n",
    "    \"\"\"\n",
    "    seq2seq模型预测时，与一般的模型是有区别的，这里Encoder部分直接预测得到输出，\n",
    "    Decoder部分需要一次预测一个位置的输出，并把当前位置的输出作为下一时刻的输入。\n",
    "    所以decoder部分需要自己写一个循环，预测每个时刻输出，最后拼接到一起。结束的判断要么达到最大长度，要么预测出结束符\"<EOS>\"。\n",
    "    \n",
    "    \"\"\"\n",
    "    text_words = input_text.split()[:maxlen]\n",
    "    input_id = [vocab2id[w] if w in vocab2id else vocab2id[\"<UNK>\"] for w in text_words]\n",
    "    input_id = [vocab2id[\"<GO>\"]] + input_id + [vocab2id[\"<EOS>\"]]\n",
    "    if len(input_id) < maxlen:\n",
    "        input_id = input_id + [vocab2id[\"<PAD>\"]] * (maxlen-len(input_id))\n",
    "\n",
    "    input_source = np.array([input_id])\n",
    "    input_target = np.array([vocab2id[\"<GO>\"]])\n",
    "    \n",
    "    # 编码器encoder预测输出\n",
    "    enc_outputs, enc_state_h, enc_state_c = encoder_model.predict([input_source])\n",
    "    dec_inputs = input_target\n",
    "    dec_states_inputs = [enc_state_h, enc_state_c]\n",
    "\n",
    "    result_id = []\n",
    "    result_text = []\n",
    "    for i in range(maxlen):\n",
    "        # 解码器decoder预测输出\n",
    "        dense_outputs, dec_state_h, dec_state_c = decoder_model.predict([enc_outputs, dec_inputs]+dec_states_inputs)\n",
    "        pred_id = np.argmax(dense_outputs[0][0])\n",
    "        result_id.append(pred_id)\n",
    "        result_text.append(id2vocab[pred_id])\n",
    "        if id2vocab[pred_id] == \"<EOS>\":\n",
    "            break\n",
    "        dec_inputs = np.array([[pred_id]])\n",
    "        dec_states_inputs = [dec_state_h, dec_state_c]\n",
    "    return result_id, result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  你 在 干 什么 呢\n",
      "Output:  ['<EOS>'] [3]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"你 在 干 什么 呢\"\n",
    "result_id, result_text = infer_predict(input_text, encoder_model, decoder_model, config.maxlen)\n",
    "\n",
    "print(\"Input: \", input_text)\n",
    "print(\"Output: \", result_text, result_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def infer_encoder_output(input_text, encoder, maxlen=10):\n",
    "    text_words = input_text.split()[:maxlen]\n",
    "    input_id = [vocab2id[w] if w in vocab2id else vocab2id[\"<UNK>\"] for w in text_words]\n",
    "    input_id = [vocab2id[\"<GO>\"]] + input_id + [vocab2id[\"<EOS>\"]]\n",
    "    if len(input_id) < maxlen:\n",
    "        input_id = input_id + [vocab2id[\"<PAD>\"]] * (maxlen-len(input_id))\n",
    "    input_source = np.array([input_id])\n",
    "    # 编码器encoder预测输出\n",
    "    enc_outputs, enc_state_h, enc_state_c = encoder.predict([input_source])\n",
    "    enc_state_outputs = [enc_state_h, enc_state_c]\n",
    "    return enc_outputs, enc_state_outputs\n",
    "\n",
    "\n",
    "def infer_beam_search(enc_outputs, enc_state_outputs, decoder, maxlen=10, k=5):\n",
    "    dec_inputs = [vocab2id[\"<GO>\"]]\n",
    "    states_curr = {0: enc_state_outputs}\n",
    "    seq_scores = [[dec_inputs, 1.0, 0]]\n",
    "    \n",
    "    for _ in range(maxlen):\n",
    "        cands = list()\n",
    "        states_prev = states_curr\n",
    "        for i in range(len(seq_scores)):\n",
    "            seq, score, state_id = seq_scores[i]\n",
    "            dec_inputs = np.array(seq[-1:])\n",
    "            dec_states_inputs = states_prev[state_id]\n",
    "            # 解码器decoder预测输出\n",
    "            dense_outputs, dec_state_h, dec_state_c = decoder.predict([enc_outputs, dec_inputs]+dec_states_inputs)\n",
    "            prob = dense_outputs[0][0]\n",
    "            states_curr[i] = [dec_state_h, dec_state_c]\n",
    "\n",
    "\n",
    "            for j in range(len(prob)):\n",
    "                cand = [seq + [j], score * prob[j], i]\n",
    "                cands.append(cand)\n",
    "            \n",
    "        seq_scores = heapq.nlargest(k, cands, lambda d: d[1])\n",
    "            \n",
    "    res = \" \".join([id2vocab[i] for i in seq_scores[0][0]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  你 在 干 什么 呢\n",
      "Output:  <GO> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"你 在 干 什么 呢\"\n",
    "\n",
    "enc_outputs, enc_state_outputs = infer_encoder_output(input_text, encoder_model)\n",
    "res = infer_beam_search(enc_outputs, enc_state_outputs, decoder_model)\n",
    "\n",
    "print(\"Input: \", input_text)\n",
    "print(\"Output: \", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
